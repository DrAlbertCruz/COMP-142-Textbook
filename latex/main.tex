\documentclass[letterpaper, 10pt]{book}
\usepackage[margin=1.5in]{geometry}
\usepackage[acronym]{glossaries}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{enumitem}

\makeglossaries
\newacronym{msb}{MSB}{most significant bit}
\newacronym{lsb}{LSB}{least significant bit}
\newglossaryentry{overflow}{name=overflow,description={%
    Exceeding the capacity of a binary number with fixed number of digits
}}
\newglossaryentry{unsigned}{name=unsigned,description={%
    A data type that allows for only positive numbers or operation that assumes the operands are positive numbers
}}

\newcommand*{\example}[1]{\vspace{1em}\noindent
    \colorbox{blue!10}{\noindent
        \begin{minipage}{\textwidth}
            \textbf{Example \thechapter.\arabic{examples}}\stepcounter{examples}
            #1
        \end{minipage}
    }\vspace{1em}
}

\begin{document}

\newcounter{examples}{1}

\section{Preface\label{sec:preface}}

This textbook is an open-source document that meets the requirements of COMP 142 Computer Architecture and Organization. The goal of the class is to study the organization and behavior of real computer systems at the assembly-language level, the mapping of statements and constructs in a high-level language onto sequences of machine instructions is studied, as well as the internal representation of simple data types and structures. It also covers numerical computation, noting the various data representation errors and potential procedural errors.

The general topics covered by the class are:

\begin{enumerate}
\item Bits, bytes, and words
\item Numeric data representation and number bases
\item Fixed- and floating-point systems
\item Signed and twos-complement representations
\item Representation of nonnumeric data (character codes, graphical data)
\item Representation of records and arrays
\item Basic organization of the von Neumann machine
\item Control unit; instruction fetch, decode, and execution
    Instruction sets and types (data manipulation, control, I/O)
\item Assembly/machine language programming
\item Instruction formats
\item Addressing modes
\item Subroutine call and return mechanisms
\item I/O and interrupts
\end{enumerate}

\chapter{Number Bases\label{sec:numbers}}
\setcounter{examples}{1}

A positional system is a numeral system in which the contribution of a digit to the value of a number 
is the value of the digit multiplied by a factor determined by the position of the digit. In early 
numeral systems, such as Roman numerals, a digit has only one value: I means one, X means ten and C 
a hundred (however, the value may be negated if placed before another digit). In modern positional 
systems, such as the decimal system, the position of the digit means that its value must be multiplied 
by some value: in 555, the three identical symbols represent five hundreds, five tens, and five units, 
respectively, due to their different positions in the digit string. 

Among the earliest systems was the Babylonian numeral system. It used base 60. It was the first 
positional system to be developed, and its influence is present today in the way time and angles are 
counted in tallies related to 60, such as 60 minutes in an hour and 360 degrees in a circle. Today, 
the Hinduâ€“Arabic numeral system (base-10) is the most commonly used system globally. However, 
the binary numeral system (base-2) is used in almost all computers and electronic devices because it 
is easier to implement efficiently in electronic circuits. 

\section{Base-2\label{sec:data:bases}}

You can think of a number base as the way to represent a number. The value of the number does not 
change when transitioning between number bases. Most people use a base of 10, also known as decimal. 
For example, 667 is a decimal number. When you work with numbers of different bases, write the number 
in parenthesis with the base in subscript, for example: $667_{10}$. Binary numbers are base 2. 
$667_{10}$ in base 2 is representated as $1010011011_2$. 

When spoken, binary numerals are usually read digit-by-digit, in order to distinguish them from 
decimal numerals. For example, $1010011011_2$ is pronounced \textit{one zero one zero zero one 
one zero one one}. It would be confusing to refer to the number as \textit{one billion ten million 
eleven thousand and eleven} which represents a different value. Note that the number base should 
not change the intrinsic value of a number.

The order of the digits in a binary number represents their power of two. The right-most digit is 
called the \acrlong{lsb} (\acrshort{lsb}) represents the power of $2^0$. The left-most digit is called 
the \acrlong{msb} (\acrshort{msb}) represents the power of $2^{n-1}$ where $n$ is the length of the 
sequence. For example, with $1010011011_2$ the LSB is 1, representing $2^0$, and the MSB is $2^9$ 
because the sequence is 10 bits long. Typically with computers, there is a fixed number of digits.

\example{Convert $1010011011_2$ to decimal by expanding the powers of two. The most straightforeward %
way to convert this number is to expand it in of powers of two:%
%
\begin{equation}\label{sec:data:bases:667bin}%
	1 \times 2^9 + 0 \times 2^8 + 1 \times 2^7 + 0 \times 2^6 + 0 \times 2^5 + 1 \times 2^4 
    + 1 \times 2^3 + 0 \times 2^2 + 1 \times 2^1 + 1 \times 2^0
\end{equation}%
Note that we write out all powers of two starting with $n-1$. In this case $n=10$ because there %
ten digits. Begining with the \acrshort{msb} and ending with the \acrshort{lsb} copy 0 or 1 %
based on the corresponding digit in the binary representation of the number. This may seem cumbersome %
but after some time you will memorize the powers of 2 and it will become easier.}


\subsection{Converting to Base-2\label{sec:data:bases:bin}}

Expanding the number in terms of powers of two is the simplest way to convert a decimal number to binary 
(such as in Equation \ref{sec:data:bases:667bin}). To do so, prepare a table with the power of two that 
is just less than the magnitude of the number you are converting. 
For $667_{10}$, this is $512_{10}$ or $2^9$:

\noindent
\vspace{1em}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}\hline
Power & $2^9$ & $2^8$ & $2^7$ & $2^6$ & $2^5$ & $2^4$ & $2^3$ & $2^2$ & $2^1$ & $2^0$ \\\hline\hline
Decimal & 512 & 256 & 128 & 64 & 32 & 16 & 8 & 4 & 2 & 1 \\\hline
Digit &  &  &  &  &  &  &  &  &  &  \\\hline
\end{tabular}

\vspace{1em}
Start from left to right. If you can subtract the number without it becoming negative, indicate 1 for the digit. Then, carry out the subtraction and use this new value for the next column. If you cannot carry out the subtraction without the number becoming negative, skip to the next column. Repeat this procedure for the next column.

 $667-512=155$, so we can indeed subtract $512_2$ from $667_2$. We can note 1 in the digit, and use the value of $155$ for the next column. $155-256<0$. We cannot subtract without the number becoming negative, so we note 0 as the digit for this current column. However, $155-128=27$. So we can note 1 in the digit for this next column. And so on until the last digit. If you have any remaining value beyond the right-most column you have made a mistake, check your work.

\vspace{1em}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|}\hline
Power & $2^9$ & $2^8$ & $2^7$ & $2^6$ & $2^5$ & $2^4$ & $2^3$ & $2^2$ & $2^1$ & $2^0$ \\\hline\hline
Decimal & 512 & 256 & 128 & 64 & 32 & 16 & 8 & 4 & 2 & 1 \\\hline
Digit & 1 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 1 \\\hline
\end{tabular}

\vspace{1em}
There is a more formal way to carry out this procedure, called the \textbf{divide-by-2} method. Essentially, with the previous algorithm the digit column is noting if there would be a remainder when carrying out integer division by its respective power of 2. An alternative way to convert the number is as follows.

Start with the number you want to convert. Perform an integer division by 2. Note that an integer division does not produce a fractional result. It should produce an integer and a remainder if the divisor cannot cleanly divide the dividend. Write the remainder to the right of the calculation, and write the result \textit{below} your calculation. Continue dividing by 2 until you reach a dividend of 1. The binary representation of the number is read from top-to-bottom of the remainder values.

\vfill\clearpage
\section*{Homework Questions}

\small
\begin{multicols*}{2}
   \begin{enumerate}[label=\thechapter.\arabic*]
    \item Conduct a search on the historical basis for binary numbers before they were used in %
    computing and explain how they were used by society.
    \item Explain in your own words the following concepts:
    \begin{enumerate}
        \item Most significant bit
        \item Least significant bit
        \item The largest unsigned number that can be stored in $n$ bits.
    \end{enumerate}
    \item Define the divide-by-2 method in pseudo-code.
    \item What is the largest unsigned number that can be stored in the following data types?
    \begin{enumerate}
        \item \texttt{char}
        \item 2-byte \texttt{int}
        \item 48-bit integer
    \end{enumerate}
    \item Convert the following decimal numbers to binary:
    \begin{multicols*}{2}
        \begin{enumerate}
            \item 0
            \item 1
            \item 23
            \item 59
            \item 100
            \item 1200
            \item 1092
            \item 1000000
        \end{enumerate}
    \end{multicols*}
    \item Convert the following binary numbers to decimal using the table method:\label{hw:tablemethod}
    \begin{enumerate}
        \item 0
        \item 1
        \item 1010
        \item 1111
        \item 1110101
        \item 1010100101
        \item 1000000000
        \item 1000100101
    \end{enumerate}
    \item Repeat Question \ref{hw:tablemethod} using the divide-by-2 method. 
   \end{enumerate} 
\end{multicols*}

\chapter{sec:datarepresentation}

Computers use binary numbers because they are made up of electronic components called transistors, 
which can be either in an ``on'' or ``off'' state. By using a binary numbering system, which only 
has two digits (0 and 1), computers can represent and process information using these ``on'' and 
``off'' states of transistors.

A binary number is a number expressed in the base-2 numeral system, a method of mathematical 
expression which uses only two symbols: typically 0 or 1. In more mathematical or logical contexts 
0 is treated as False and 1 is treated as True.

The base-2 numeral system is a positional notation with a base of 2. Each digit is referred to as 
a bit, or binary digit. Because of its straightforward implementation in digital electronic 
circuitry using logic gates, the binary system is used by almost all modern computers and 
computer-based devices, as a preferred system of use, over various other human techniques of 
communication, because of the underlying transitor-level components.

The modern binary number system was studied in Europe in the 16th and 17th centuries by Thomas 
Harriot, Juan Caramuel y Lobkowitz, and Gottfried Leibniz. However, systems related to binary 
numbers have appeared earlier in multiple cultures including ancient Egypt, China, and India. 
Leibniz was specifically inspired by the \textit{I Ching}, a classical Chinese text from the 9th century BCE. 

The purpose of thise chapter is to understand binary numbers. Examples will describe how to convert
from decimal numbers to binary. Alternative representations, such as hexadecimal, will also be
covered. Finally, TODO: how they are grouped in the computer using bytes or bibytes, 



It is important to note the largest positive integer that can be stored for a binary sequence of a 
given length to avoid a concept called \gls{overflow}. For \gls{unsigned} numbers this is defined as: %

%
\begin{equation} \label{eq:sizeofunsignedint}
    2^n - 1
\end{equation}
%
Where $n$ is the number of digits in the binary sequence. 

\example{What is the largest number that you can store in an unsigned C-language \texttt{int} data type? %
Note that \texttt{int} is 32 bits, so $n=32$
\begin{align*}%
    & 2^n-1 \\
    & 2^{32} - 1 = 4,294,967,295
\end{align*}%
Perhaps this is somewhat shocking. A C-language \texttt{int} cannot hold numbers greater than four billion.
}

\example{Suppose that you want to use binary numbers to encode specific letters of the Spanish language %
alphabet which has 27 letters. At least how many bits will you need to uniquely encode each letter?
\begin{align*}
    & 2^n-1 \geq 27 \\
    & 2^n \geq 28 \\
    & n \geq \log_2 28 \\
    & n \geq 4.8 \approx 5
\end{align*}
You cannot have a fractional number of digits, so it must be at least 5 bits.
}

\printglossary[type=\acronymtype]

\printglossary
 
\end{document}
